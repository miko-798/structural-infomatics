{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Convolutional Q8 Classification\n",
    "\n",
    "Using pssm: ~31%  accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Flatten, Reshape\n",
    "from keras.layers.convolutional import Convolution1D\n",
    "from keras import optimizers\n",
    "from keras.regularizers import l2\n",
    "\n",
    "\n",
    "import cullpdb_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants and Hyperparameters\n",
    "Declare constants about data such as the length of a protein and the number of possible residues and classes.\n",
    "<br><br>\n",
    "Declare hyperparameters about model such as learning rate, number of epochs of training (how many iterations through the entire data set to train for), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NUM_RESIDUES = 700           # per protein\n",
    "RESIDUE_SIZE = 22   \n",
    "NUM_CLASSES = 9              # 8 + 'NoSeq'\n",
    "PSSM_SIZE = 22\n",
    "NUM_FEATURES = RESIDUE_SIZE  # size of one hot vector per residue\n",
    "\n",
    "PSSM = True\n",
    "if PSSM:\n",
    "    NUM_FEATURES += PSSM_SIZE\n",
    "\n",
    "FILTERS = 1       # Dimensions output by conv layer\n",
    "WINDOW_SIZE = 11  # \"scope\" of convolution (ie 11 total residues)\n",
    "\n",
    "TWO_D = True\n",
    "if TWO_D:\n",
    "    INPUT_SHAPE = (NUM_RESIDUES, NUM_FEATURES)  # see below\n",
    "else:\n",
    "    INPUT_SHAPE = (NUM_RESIDUES * NUM_FEATURES,)\n",
    "OUTPUT_SIZE = NUM_CLASSES*NUM_RESIDUES      # output matrix holding predictions\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "GAMMA = 0  # momentum coefficient\n",
    "EPOCHS = 500  # iterations of training, total dataset covered once each epoch\n",
    "LOSS='categorical_crossentropy'\n",
    "OPTIMIZER = optimizers.SGD(lr=LEARNING_RATE, momentum=GAMMA, nesterov=False)\n",
    "\n",
    "SHOW_ACCURACY = True  # set to False for quicker train ops\n",
    "\n",
    "SAVE_FILE = \"models/conv-filtered-4-03\"\n",
    "DATA = \"data/cullpdb+profile_6133.npy.gz\"\n",
    "DATA_FILTERED = \"data/cullpdb+profile_6133_filtered.npy.gz\"\n",
    "DATA_TEST = \"data/cb513+profile_split1.npy.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "<b>Data:</b><br> _x represents input proteins, _y represents target structure classifications (each as one-hot vectors) <br><br>\n",
    "<b>Data Shape:</b><br> First dimension represents number of proteins, second number of residues per protein, and third size of residue or structure vector.<br> For example, train_x without pssm is shape (5600, 700, 22): it is an <b>m \\* n \\* p</b> matrix where there are <b>m</b> proteins (each row), <b>n</b> residues per protein (each column), and <b>p</b> sized vectors to represent a single residue or a single structure (each \"slice\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading protein residues and labels...\n",
      "Loading file from C:\\SANJAY\\CS\\Projects\\sdscbio\\data\\cullpdb+profile_6133_filtered.npy.gz...\n",
      "File Loaded.\n",
      "Loaded protein residues and labels.\n",
      "Reshaping...\n",
      "Reshaped\n",
      "Loading file from C:\\SANJAY\\CS\\Projects\\sdscbio\\data\\cb513+profile_split1.npy.gz...\n",
      "File Loaded.\n",
      "Residues:\n",
      "FDYQTVYFANQYGLRTIELGESEFVDNTLDNQHKXVIKAAWGGGYTNRNNVVINFKVDESLCDNLYFKDTDQPLVPXPASYYTLASDRIAIPKGQIXAGVEVQLTDDFFADEKSISENYVIPLLXTNVQGADSILQGKPVVENPVLTNAGDWSILPQNFVLYAVKYVNPWHGEYLRRGIDHATVAGTSKDIIRHEQFVENDEVVNISTKSXKDNLLTLKTKDESGKDISYTVRLSFAEDGSCTVHSGSQNVVVSGSGKFVSKGEKNSLGGKDRNAIYLDYTVNLTDNNIQLATKDTLVLRTRNVYGGKSLEVVRK-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Labels:\n",
      "LLLLEEELSLSEEEEEEELSLLSSSLLHHHHTTEEEEEEEEESSSSLLSLEEEEEEELGGGGTTLEETTTLLBLEELLGGGEEESLSEEEELTTLSEEEEEEEELHHHHHSGGGGSSLEEEEEEEEEEESSSEELLLEESSSSLLTTLGGGEEELLLSEEEEEEEEELTTLEEEEEEEEEEEEETTEEEEEEELLSSGGGSEEEEEEESSSSEEEEEEEEELTTSLEEEEEEEEEELTTSEEEEEELSTTLEEEEEEEEEEEEETTLGGGSLEEEEEEEEEEEETTTTEEEEEEEEEEEEELLLLSEEELLEELL-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "train_x: (5534, 700, 44)\n",
      "train_y (5534, 6300)\n",
      "test_x: (514, 700, 44)\n",
      "test_y: (514, 6300)\n"
     ]
    }
   ],
   "source": [
    "train = cullpdb_loader.load_residues(DATA_FILTERED, split=False, two_d=TWO_D, pssm=PSSM)  # load from my helper file\n",
    "\n",
    "test = cullpdb_loader.load_cb513(DATA_TEST, two_d=TWO_D, pssm=PSSM)\n",
    "\n",
    "# train, validation, and test were loaded as tuples of (input, output);\n",
    "# here we unpack them into separate variables:\n",
    "train_x, train_y = train\n",
    "test_x, test_y = test\n",
    "\n",
    "# print a protein to see example representation (with character labels instead of one-hot vectors)\n",
    "cullpdb_loader.print_residues(train_x[0], labels=train_y[0], two_d=TWO_D)\n",
    "\n",
    "# reshape the labels into a 2D matrix to make accuracy checks easier later on\n",
    "train_y = train_y.reshape(len(train_y), NUM_CLASSES*NUM_RESIDUES)\n",
    "test_y = test_y.reshape(len(test_y), NUM_CLASSES*NUM_RESIDUES)\n",
    "\n",
    "\n",
    "# print to verify data was loaded in correct shapes:\n",
    "print(\"train_x:\", train_x.shape)\n",
    "print(\"train_y\", train_y.shape)\n",
    "print(\"test_x:\", test_x.shape)\n",
    "print(\"test_y:\", test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Accuracy Metric\n",
    "\n",
    "The default Keras accuracy metric does not compare observations and targets over multiple dimensions. A custom method to find  accuracy must be defined.\n",
    "<br><br>\n",
    "Here, a <b>mask</b> is created -- a matrix with ones where the target labels have labels that are not 'NoSeq', and zeros where the target labels are 'NoSeq'. We can then do a comparison between observed and target labels, and by multiplying the resulting boolean matrix by this mask, we ignore any right/wrong labels in the trailing 'NoSeq' region (that exists only to pad the protein to the correct length).\n",
    "<br><br>\n",
    "This gives an accuracy metric depending only on the non-'NoSeq' labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Second custom accuracy: ignore trailing noseq's\n",
    "def custom_acc(true, obs):\n",
    "    print(\"Using custom accuracy\")\n",
    "    if not SHOW_ACCURACY:\n",
    "        return K.constant(float('NaN'))\n",
    "    \n",
    "    # -1 = placeholder for whatever's left\n",
    "    obs = K.reshape(obs, [-1, 700, 9])\n",
    "    true = K.reshape(true, [-1, 700, 9])\n",
    "    \n",
    "    # convert one-hot vectors for residues to scalars\n",
    "    true_vals = K.argmax(true, axis=2)\n",
    "    obs_vals = K.argmax(obs, axis=2)\n",
    "    \n",
    "    # mask is 2D matrix with 1s in indices that are residues\n",
    "    # and 0s in indices that are 'NoSeq'\n",
    "    # subtract all 8's to shift 'NoSeq' values to zero\n",
    "    mask = K.sign(K.abs(true_vals - 8*K.ones_like(true_vals, dtype='int64')))\n",
    "    mask = K.cast(mask, dtype=K.floatx())\n",
    "    # 1D vector with each index the number of non-'NoSeq' residues \n",
    "    # in corresponding protein\n",
    "    length = K.sum(mask, axis=1)\n",
    "    \n",
    "    # compare observed and predicted values (cast from boolean to 1s and 0s),\n",
    "    # then multiply by mask to nullify any trailing 'NoSeq' equalities\n",
    "    comparison = K.cast(K.equal(true_vals, obs_vals), dtype=K.floatx())\n",
    "    comparison = comparison * mask\n",
    "    \n",
    "    # and return average\n",
    "    return K.sum(comparison) / K.sum(length)\n",
    "    \n",
    "\n",
    "# not working\n",
    "def custom_loss(obs, pred):\n",
    "    pred = tf.Variable(pred)\n",
    "    pred.set_shape([None, NUM_RESIDUES, NUM_CLASSES])\n",
    "    obs = tf.Variable(obs)\n",
    "    obs.set_shape([None, NUM_RESIDUES, NUM_CLASSES])\n",
    "    return tf.nn.softmax_cross_entropy_with_logits(labels=pred, logits=obs, name='custom-loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "The model is constructed to currently have 3 convolutional layers.<br><br>\n",
    "A convolutional window \"slides\" across the input, each time taking the nearest <i>WINDOW_SIZE</i> number of features (residues) as inputs and outputing a single vector of dimension <i>FILTERS</i>. It performs this operation similarly to a usual perceptron, with a weight matrix and a gate function/nonlinearity.\n",
    "<br><br>\n",
    "This 3d data (samples, Protein Length, <i>FILTERS</i>) is flattened to 2d (samples, Length \\* <i>FILTERS</i>). Finally a \"dense\", fully connected layer (A vanilla neural network/multiperceptron layer) reduces the dimensionality of the data from the previous <i>FILTERS</i> dimensions to <i>OUTPUT_SIZE</i> dimensions (here 9, 8 for each secondary structure class and 1 for None)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# border_mode indicates how the convolution handles the edges of the input (where the window \"sticks out\").\n",
    "# The 'same' setting pads the inputs with zeros on either side.\n",
    "# Only the first layer requires an input_shape parameter; successive layers infer it from within the model.\n",
    "\n",
    "# 1st layer\n",
    "model.add(Convolution1D(\n",
    "        FILTERS, WINDOW_SIZE, activation='tanh', border_mode='same', input_shape=INPUT_SHAPE))\n",
    "# 2nd layer\n",
    "model.add(Convolution1D(\n",
    "        FILTERS, WINDOW_SIZE, activation='tanh', border_mode='same'))\n",
    "# 3rd layer\n",
    "model.add(Convolution1D(\n",
    "        FILTERS, WINDOW_SIZE, activation='tanh', border_mode='same'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "# 'lecun_uniform' indicates that the weights should be initialized to small random values in a certain normal distribution.\n",
    "model.add(Dense(OUTPUT_SIZE, init='lecun_uniform', name=\"OutputLayer\", activation='softmax'))\n",
    "#model.add(Reshape((NUM_RESIDUES, NUM_CLASSES)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model given a loss function, optimizer, and learning rate (specified above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using custom accuracy\n"
     ]
    }
   ],
   "source": [
    "# optimizer= takes either string or optimizer object\n",
    "model.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=[custom_acc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model on training data against target training labels, show accuracy on validation data each epoch\n",
    "Here, the <b>val_loss</b> and <b>val_acc</b> are the loss and accuracy on the test data. The loss is output by the cost function and has no absolute meaning by value, but relative values are important: we want them to decrease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5534 samples, validate on 514 samples\n",
      "Epoch 1/500\n",
      "26s - loss: 5238.3809 - custom_acc: 0.2463 - val_loss: 4962.2681 - val_custom_acc: 0.2719\n",
      "Epoch 2/500\n",
      "25s - loss: 5013.0127 - custom_acc: 0.3110 - val_loss: 4931.4504 - val_custom_acc: 0.2853\n",
      "Epoch 3/500\n",
      "24s - loss: 4992.1838 - custom_acc: 0.3235 - val_loss: 4918.7086 - val_custom_acc: 0.2912\n",
      "Epoch 4/500\n",
      "24s - loss: 4981.8076 - custom_acc: 0.3299 - val_loss: 4911.2014 - val_custom_acc: 0.2946\n",
      "Epoch 5/500\n",
      "25s - loss: 4975.2151 - custom_acc: 0.3340 - val_loss: 4906.0834 - val_custom_acc: 0.2971\n",
      "Epoch 6/500\n",
      "25s - loss: 4970.5474 - custom_acc: 0.3371 - val_loss: 4902.3336 - val_custom_acc: 0.2991\n",
      "Epoch 7/500\n",
      "27s - loss: 4967.0417 - custom_acc: 0.3393 - val_loss: 4899.4577 - val_custom_acc: 0.3005\n",
      "Epoch 8/500\n",
      "25s - loss: 4964.2897 - custom_acc: 0.3410 - val_loss: 4897.1691 - val_custom_acc: 0.3014\n",
      "Epoch 9/500\n",
      "25s - loss: 4962.0516 - custom_acc: 0.3423 - val_loss: 4895.2935 - val_custom_acc: 0.3020\n",
      "Epoch 10/500\n",
      "24s - loss: 4960.1816 - custom_acc: 0.3433 - val_loss: 4893.7210 - val_custom_acc: 0.3024\n",
      "Epoch 11/500\n",
      "25s - loss: 4958.5868 - custom_acc: 0.3443 - val_loss: 4892.3788 - val_custom_acc: 0.3031\n",
      "Epoch 12/500\n",
      "24s - loss: 4957.2043 - custom_acc: 0.3450 - val_loss: 4891.2162 - val_custom_acc: 0.3034\n",
      "Epoch 13/500\n",
      "24s - loss: 4955.9896 - custom_acc: 0.3457 - val_loss: 4890.1979 - val_custom_acc: 0.3038\n",
      "Epoch 14/500\n",
      "25s - loss: 4954.9108 - custom_acc: 0.3463 - val_loss: 4889.2967 - val_custom_acc: 0.3040\n",
      "Epoch 15/500\n",
      "24s - loss: 4953.9436 - custom_acc: 0.3468 - val_loss: 4888.4926 - val_custom_acc: 0.3043\n",
      "Epoch 16/500\n",
      "25s - loss: 4953.0696 - custom_acc: 0.3474 - val_loss: 4887.7697 - val_custom_acc: 0.3047\n",
      "Epoch 17/500\n",
      "25s - loss: 4952.2743 - custom_acc: 0.3479 - val_loss: 4887.1157 - val_custom_acc: 0.3050\n",
      "Epoch 18/500\n",
      "25s - loss: 4951.5459 - custom_acc: 0.3483 - val_loss: 4886.5203 - val_custom_acc: 0.3051\n",
      "Epoch 19/500\n",
      "25s - loss: 4950.8757 - custom_acc: 0.3486 - val_loss: 4885.9769 - val_custom_acc: 0.3054\n",
      "Epoch 20/500\n",
      "24s - loss: 4950.2558 - custom_acc: 0.3489 - val_loss: 4885.4772 - val_custom_acc: 0.3057\n",
      "Epoch 21/500\n",
      "24s - loss: 4949.6800 - custom_acc: 0.3492 - val_loss: 4885.0160 - val_custom_acc: 0.3058\n",
      "Epoch 22/500\n",
      "24s - loss: 4949.1430 - custom_acc: 0.3495 - val_loss: 4884.5894 - val_custom_acc: 0.3059\n",
      "Epoch 23/500\n",
      "25s - loss: 4948.6408 - custom_acc: 0.3498 - val_loss: 4884.1937 - val_custom_acc: 0.3061\n",
      "Epoch 24/500\n",
      "25s - loss: 4948.1694 - custom_acc: 0.3500 - val_loss: 4883.8247 - val_custom_acc: 0.3062\n",
      "Epoch 25/500\n",
      "25s - loss: 4947.7255 - custom_acc: 0.3502 - val_loss: 4883.4800 - val_custom_acc: 0.3061\n",
      "Epoch 26/500\n",
      "26s - loss: 4947.3065 - custom_acc: 0.3505 - val_loss: 4883.1570 - val_custom_acc: 0.3063\n",
      "Epoch 27/500\n",
      "25s - loss: 4946.9102 - custom_acc: 0.3506 - val_loss: 4882.8540 - val_custom_acc: 0.3066\n",
      "Epoch 28/500\n",
      "24s - loss: 4946.5344 - custom_acc: 0.3509 - val_loss: 4882.5690 - val_custom_acc: 0.3067\n",
      "Epoch 29/500\n",
      "24s - loss: 4946.1772 - custom_acc: 0.3510 - val_loss: 4882.2997 - val_custom_acc: 0.3067\n",
      "Epoch 30/500\n",
      "24s - loss: 4945.8370 - custom_acc: 0.3512 - val_loss: 4882.0455 - val_custom_acc: 0.3067\n",
      "Epoch 31/500\n",
      "24s - loss: 4945.5124 - custom_acc: 0.3514 - val_loss: 4881.8049 - val_custom_acc: 0.3067\n",
      "Epoch 32/500\n",
      "24s - loss: 4945.2023 - custom_acc: 0.3516 - val_loss: 4881.5766 - val_custom_acc: 0.3067\n",
      "Epoch 33/500\n",
      "26s - loss: 4944.9052 - custom_acc: 0.3518 - val_loss: 4881.3597 - val_custom_acc: 0.3069\n",
      "Epoch 34/500\n",
      "24s - loss: 4944.6207 - custom_acc: 0.3519 - val_loss: 4881.1535 - val_custom_acc: 0.3069\n",
      "Epoch 35/500\n",
      "24s - loss: 4944.3477 - custom_acc: 0.3521 - val_loss: 4880.9575 - val_custom_acc: 0.3070\n",
      "Epoch 36/500\n",
      "24s - loss: 4944.0851 - custom_acc: 0.3522 - val_loss: 4880.7696 - val_custom_acc: 0.3071\n",
      "Epoch 37/500\n",
      "24s - loss: 4943.8324 - custom_acc: 0.3523 - val_loss: 4880.5910 - val_custom_acc: 0.3071\n",
      "Epoch 38/500\n",
      "24s - loss: 4943.5889 - custom_acc: 0.3524 - val_loss: 4880.4199 - val_custom_acc: 0.3072\n",
      "Epoch 39/500\n",
      "24s - loss: 4943.3541 - custom_acc: 0.3525 - val_loss: 4880.2558 - val_custom_acc: 0.3072\n",
      "Epoch 40/500\n",
      "24s - loss: 4943.1272 - custom_acc: 0.3527 - val_loss: 4880.0988 - val_custom_acc: 0.3072\n",
      "Epoch 41/500\n",
      "24s - loss: 4942.9080 - custom_acc: 0.3528 - val_loss: 4879.9482 - val_custom_acc: 0.3072\n",
      "Epoch 42/500\n",
      "24s - loss: 4942.6958 - custom_acc: 0.3530 - val_loss: 4879.8033 - val_custom_acc: 0.3072\n",
      "Epoch 43/500\n",
      "24s - loss: 4942.4903 - custom_acc: 0.3531 - val_loss: 4879.6641 - val_custom_acc: 0.3073\n",
      "Epoch 44/500\n",
      "24s - loss: 4942.2911 - custom_acc: 0.3532 - val_loss: 4879.5302 - val_custom_acc: 0.3074\n",
      "Epoch 45/500\n",
      "24s - loss: 4942.0979 - custom_acc: 0.3532 - val_loss: 4879.4014 - val_custom_acc: 0.3077\n",
      "Epoch 46/500\n",
      "24s - loss: 4941.9103 - custom_acc: 0.3533 - val_loss: 4879.2773 - val_custom_acc: 0.3078\n",
      "Epoch 47/500\n",
      "24s - loss: 4941.7279 - custom_acc: 0.3534 - val_loss: 4879.1574 - val_custom_acc: 0.3078\n",
      "Epoch 48/500\n",
      "24s - loss: 4941.5505 - custom_acc: 0.3535 - val_loss: 4879.0419 - val_custom_acc: 0.3080\n",
      "Epoch 49/500\n",
      "24s - loss: 4941.3781 - custom_acc: 0.3536 - val_loss: 4878.9303 - val_custom_acc: 0.3079\n",
      "Epoch 50/500\n",
      "24s - loss: 4941.2099 - custom_acc: 0.3537 - val_loss: 4878.8223 - val_custom_acc: 0.3081\n",
      "Epoch 51/500\n",
      "24s - loss: 4941.0463 - custom_acc: 0.3538 - val_loss: 4878.7176 - val_custom_acc: 0.3082\n",
      "Epoch 52/500\n",
      "24s - loss: 4940.8867 - custom_acc: 0.3539 - val_loss: 4878.6169 - val_custom_acc: 0.3082\n",
      "Epoch 53/500\n",
      "24s - loss: 4940.7310 - custom_acc: 0.3540 - val_loss: 4878.5188 - val_custom_acc: 0.3082\n",
      "Epoch 54/500\n",
      "24s - loss: 4940.5791 - custom_acc: 0.3541 - val_loss: 4878.4236 - val_custom_acc: 0.3081\n",
      "Epoch 55/500\n",
      "24s - loss: 4940.4308 - custom_acc: 0.3542 - val_loss: 4878.3318 - val_custom_acc: 0.3082\n",
      "Epoch 56/500\n",
      "24s - loss: 4940.2858 - custom_acc: 0.3542 - val_loss: 4878.2427 - val_custom_acc: 0.3082\n",
      "Epoch 57/500\n",
      "24s - loss: 4940.1441 - custom_acc: 0.3542 - val_loss: 4878.1563 - val_custom_acc: 0.3081\n",
      "Epoch 58/500\n",
      "25s - loss: 4940.0055 - custom_acc: 0.3543 - val_loss: 4878.0725 - val_custom_acc: 0.3081\n",
      "Epoch 59/500\n",
      "26s - loss: 4939.8699 - custom_acc: 0.3544 - val_loss: 4877.9908 - val_custom_acc: 0.3079\n",
      "Epoch 60/500\n",
      "26s - loss: 4939.7371 - custom_acc: 0.3545 - val_loss: 4877.9115 - val_custom_acc: 0.3078\n",
      "Epoch 61/500\n",
      "26s - loss: 4939.6071 - custom_acc: 0.3545 - val_loss: 4877.8345 - val_custom_acc: 0.3080\n",
      "Epoch 62/500\n",
      "26s - loss: 4939.4795 - custom_acc: 0.3546 - val_loss: 4877.7596 - val_custom_acc: 0.3081\n",
      "Epoch 63/500\n",
      "26s - loss: 4939.3546 - custom_acc: 0.3547 - val_loss: 4877.6869 - val_custom_acc: 0.3080\n",
      "Epoch 64/500\n",
      "26s - loss: 4939.2322 - custom_acc: 0.3547 - val_loss: 4877.6157 - val_custom_acc: 0.3079\n",
      "Epoch 65/500\n",
      "26s - loss: 4939.1120 - custom_acc: 0.3548 - val_loss: 4877.5467 - val_custom_acc: 0.3079\n",
      "Epoch 66/500\n",
      "26s - loss: 4938.9940 - custom_acc: 0.3549 - val_loss: 4877.4797 - val_custom_acc: 0.3078\n",
      "Epoch 67/500\n",
      "26s - loss: 4938.8782 - custom_acc: 0.3549 - val_loss: 4877.4140 - val_custom_acc: 0.3077\n",
      "Epoch 68/500\n",
      "26s - loss: 4938.7644 - custom_acc: 0.3550 - val_loss: 4877.3501 - val_custom_acc: 0.3076\n",
      "Epoch 69/500\n",
      "25s - loss: 4938.6526 - custom_acc: 0.3551 - val_loss: 4877.2876 - val_custom_acc: 0.3076\n",
      "Epoch 70/500\n",
      "24s - loss: 4938.5428 - custom_acc: 0.3551 - val_loss: 4877.2267 - val_custom_acc: 0.3077\n",
      "Epoch 71/500\n",
      "24s - loss: 4938.4348 - custom_acc: 0.3552 - val_loss: 4877.1673 - val_custom_acc: 0.3078\n",
      "Epoch 72/500\n",
      "24s - loss: 4938.3286 - custom_acc: 0.3553 - val_loss: 4877.1094 - val_custom_acc: 0.3079\n",
      "Epoch 73/500\n",
      "24s - loss: 4938.2242 - custom_acc: 0.3553 - val_loss: 4877.0526 - val_custom_acc: 0.3079\n",
      "Epoch 74/500\n",
      "24s - loss: 4938.1214 - custom_acc: 0.3554 - val_loss: 4876.9976 - val_custom_acc: 0.3079\n",
      "Epoch 75/500\n",
      "24s - loss: 4938.0203 - custom_acc: 0.3555 - val_loss: 4876.9434 - val_custom_acc: 0.3078\n",
      "Epoch 76/500\n",
      "24s - loss: 4937.9208 - custom_acc: 0.3555 - val_loss: 4876.8909 - val_custom_acc: 0.3079\n",
      "Epoch 77/500\n",
      "24s - loss: 4937.8228 - custom_acc: 0.3556 - val_loss: 4876.8391 - val_custom_acc: 0.3080\n",
      "Epoch 78/500\n",
      "24s - loss: 4937.7262 - custom_acc: 0.3557 - val_loss: 4876.7888 - val_custom_acc: 0.3080\n",
      "Epoch 79/500\n",
      "24s - loss: 4937.6311 - custom_acc: 0.3557 - val_loss: 4876.7396 - val_custom_acc: 0.3079\n",
      "Epoch 80/500\n",
      "24s - loss: 4937.5373 - custom_acc: 0.3558 - val_loss: 4876.6916 - val_custom_acc: 0.3079\n",
      "Epoch 81/500\n",
      "24s - loss: 4937.4449 - custom_acc: 0.3559 - val_loss: 4876.6446 - val_custom_acc: 0.3080\n",
      "Epoch 82/500\n",
      "24s - loss: 4937.3538 - custom_acc: 0.3559 - val_loss: 4876.5987 - val_custom_acc: 0.3081\n",
      "Epoch 83/500\n",
      "24s - loss: 4937.2639 - custom_acc: 0.3560 - val_loss: 4876.5537 - val_custom_acc: 0.3080\n",
      "Epoch 84/500\n",
      "24s - loss: 4937.1753 - custom_acc: 0.3561 - val_loss: 4876.5097 - val_custom_acc: 0.3081\n",
      "Epoch 85/500\n",
      "24s - loss: 4937.0878 - custom_acc: 0.3561 - val_loss: 4876.4666 - val_custom_acc: 0.3082\n",
      "Epoch 86/500\n",
      "24s - loss: 4937.0015 - custom_acc: 0.3562 - val_loss: 4876.4242 - val_custom_acc: 0.3083\n",
      "Epoch 87/500\n",
      "24s - loss: 4936.9164 - custom_acc: 0.3563 - val_loss: 4876.3829 - val_custom_acc: 0.3082\n",
      "Epoch 88/500\n",
      "24s - loss: 4936.8322 - custom_acc: 0.3564 - val_loss: 4876.3426 - val_custom_acc: 0.3082\n",
      "Epoch 89/500\n",
      "24s - loss: 4936.7492 - custom_acc: 0.3564 - val_loss: 4876.3028 - val_custom_acc: 0.3083\n",
      "Epoch 90/500\n",
      "24s - loss: 4936.6672 - custom_acc: 0.3565 - val_loss: 4876.2638 - val_custom_acc: 0.3083\n",
      "Epoch 91/500\n",
      "24s - loss: 4936.5862 - custom_acc: 0.3566 - val_loss: 4876.2254 - val_custom_acc: 0.3082\n",
      "Epoch 92/500\n",
      "24s - loss: 4936.5061 - custom_acc: 0.3566 - val_loss: 4876.1882 - val_custom_acc: 0.3082\n",
      "Epoch 93/500\n",
      "24s - loss: 4936.4270 - custom_acc: 0.3566 - val_loss: 4876.1516 - val_custom_acc: 0.3082\n",
      "Epoch 94/500\n",
      "24s - loss: 4936.3488 - custom_acc: 0.3567 - val_loss: 4876.1155 - val_custom_acc: 0.3083\n",
      "Epoch 95/500\n",
      "24s - loss: 4936.2715 - custom_acc: 0.3568 - val_loss: 4876.0803 - val_custom_acc: 0.3082\n",
      "Epoch 96/500\n",
      "24s - loss: 4936.1950 - custom_acc: 0.3569 - val_loss: 4876.0455 - val_custom_acc: 0.3082\n",
      "Epoch 97/500\n",
      "24s - loss: 4936.1195 - custom_acc: 0.3569 - val_loss: 4876.0116 - val_custom_acc: 0.3083\n",
      "Epoch 98/500\n",
      "24s - loss: 4936.0447 - custom_acc: 0.3570 - val_loss: 4875.9783 - val_custom_acc: 0.3083\n",
      "Epoch 99/500\n",
      "24s - loss: 4935.9708 - custom_acc: 0.3571 - val_loss: 4875.9454 - val_custom_acc: 0.3083\n",
      "Epoch 100/500\n",
      "24s - loss: 4935.8977 - custom_acc: 0.3571 - val_loss: 4875.9134 - val_custom_acc: 0.3083\n",
      "Epoch 101/500\n",
      "24s - loss: 4935.8254 - custom_acc: 0.3572 - val_loss: 4875.8821 - val_custom_acc: 0.3084\n",
      "Epoch 102/500\n",
      "24s - loss: 4935.7538 - custom_acc: 0.3573 - val_loss: 4875.8510 - val_custom_acc: 0.3084\n",
      "Epoch 103/500\n",
      "24s - loss: 4935.6829 - custom_acc: 0.3574 - val_loss: 4875.8208 - val_custom_acc: 0.3084\n",
      "Epoch 104/500\n",
      "24s - loss: 4935.6127 - custom_acc: 0.3574 - val_loss: 4875.7908 - val_custom_acc: 0.3084\n",
      "Epoch 105/500\n",
      "24s - loss: 4935.5433 - custom_acc: 0.3575 - val_loss: 4875.7617 - val_custom_acc: 0.3084\n",
      "Epoch 106/500\n",
      "24s - loss: 4935.4746 - custom_acc: 0.3576 - val_loss: 4875.7329 - val_custom_acc: 0.3084\n",
      "Epoch 107/500\n",
      "24s - loss: 4935.4065 - custom_acc: 0.3576 - val_loss: 4875.7045 - val_custom_acc: 0.3084\n",
      "Epoch 108/500\n",
      "24s - loss: 4935.3390 - custom_acc: 0.3577 - val_loss: 4875.6768 - val_custom_acc: 0.3085\n",
      "Epoch 109/500\n",
      "24s - loss: 4935.2722 - custom_acc: 0.3577 - val_loss: 4875.6493 - val_custom_acc: 0.3086\n",
      "Epoch 110/500\n",
      "24s - loss: 4935.2060 - custom_acc: 0.3578 - val_loss: 4875.6226 - val_custom_acc: 0.3086\n",
      "Epoch 111/500\n",
      "24s - loss: 4935.1404 - custom_acc: 0.3578 - val_loss: 4875.5962 - val_custom_acc: 0.3086\n",
      "Epoch 112/500\n",
      "24s - loss: 4935.0755 - custom_acc: 0.3579 - val_loss: 4875.5701 - val_custom_acc: 0.3085\n",
      "Epoch 113/500\n",
      "24s - loss: 4935.0111 - custom_acc: 0.3580 - val_loss: 4875.5446 - val_custom_acc: 0.3084\n",
      "Epoch 114/500\n",
      "24s - loss: 4934.9474 - custom_acc: 0.3580 - val_loss: 4875.5195 - val_custom_acc: 0.3085\n",
      "Epoch 115/500\n",
      "24s - loss: 4934.8841 - custom_acc: 0.3581 - val_loss: 4875.4946 - val_custom_acc: 0.3085\n",
      "Epoch 116/500\n",
      "24s - loss: 4934.8214 - custom_acc: 0.3581 - val_loss: 4875.4705 - val_custom_acc: 0.3086\n",
      "Epoch 117/500\n",
      "24s - loss: 4934.7592 - custom_acc: 0.3582 - val_loss: 4875.4467 - val_custom_acc: 0.3087\n",
      "Epoch 118/500\n",
      "24s - loss: 4934.6976 - custom_acc: 0.3582 - val_loss: 4875.4232 - val_custom_acc: 0.3086\n",
      "Epoch 119/500\n",
      "24s - loss: 4934.6365 - custom_acc: 0.3583 - val_loss: 4875.3999 - val_custom_acc: 0.3086\n",
      "Epoch 120/500\n",
      "24s - loss: 4934.5759 - custom_acc: 0.3583 - val_loss: 4875.3771 - val_custom_acc: 0.3086\n",
      "Epoch 121/500\n",
      "24s - loss: 4934.5158 - custom_acc: 0.3584 - val_loss: 4875.3550 - val_custom_acc: 0.3086\n",
      "Epoch 122/500\n",
      "24s - loss: 4934.4562 - custom_acc: 0.3584 - val_loss: 4875.3329 - val_custom_acc: 0.3086\n",
      "Epoch 123/500\n",
      "24s - loss: 4934.3970 - custom_acc: 0.3585 - val_loss: 4875.3112 - val_custom_acc: 0.3087\n",
      "Epoch 124/500\n",
      "24s - loss: 4934.3384 - custom_acc: 0.3586 - val_loss: 4875.2897 - val_custom_acc: 0.3087\n",
      "Epoch 125/500\n",
      "24s - loss: 4934.2803 - custom_acc: 0.3586 - val_loss: 4875.2689 - val_custom_acc: 0.3087\n",
      "Epoch 126/500\n",
      "24s - loss: 4934.2225 - custom_acc: 0.3587 - val_loss: 4875.2482 - val_custom_acc: 0.3087\n",
      "Epoch 127/500\n",
      "24s - loss: 4934.1652 - custom_acc: 0.3587 - val_loss: 4875.2281 - val_custom_acc: 0.3087\n",
      "Epoch 128/500\n",
      "24s - loss: 4934.1085 - custom_acc: 0.3588 - val_loss: 4875.2079 - val_custom_acc: 0.3086\n",
      "Epoch 129/500\n",
      "24s - loss: 4934.0519 - custom_acc: 0.3589 - val_loss: 4875.1884 - val_custom_acc: 0.3086\n",
      "Epoch 130/500\n",
      "24s - loss: 4933.9960 - custom_acc: 0.3589 - val_loss: 4875.1689 - val_custom_acc: 0.3087\n",
      "Epoch 131/500\n",
      "24s - loss: 4933.9404 - custom_acc: 0.3590 - val_loss: 4875.1501 - val_custom_acc: 0.3088\n",
      "Epoch 132/500\n",
      "24s - loss: 4933.8852 - custom_acc: 0.3590 - val_loss: 4875.1312 - val_custom_acc: 0.3087\n",
      "Epoch 133/500\n",
      "24s - loss: 4933.8304 - custom_acc: 0.3591 - val_loss: 4875.1126 - val_custom_acc: 0.3088\n",
      "Epoch 134/500\n",
      "24s - loss: 4933.7760 - custom_acc: 0.3591 - val_loss: 4875.0944 - val_custom_acc: 0.3088\n",
      "Epoch 135/500\n",
      "24s - loss: 4933.7220 - custom_acc: 0.3592 - val_loss: 4875.0764 - val_custom_acc: 0.3088\n",
      "Epoch 136/500\n",
      "24s - loss: 4933.6684 - custom_acc: 0.3592 - val_loss: 4875.0586 - val_custom_acc: 0.3089\n",
      "Epoch 137/500\n",
      "24s - loss: 4933.6152 - custom_acc: 0.3593 - val_loss: 4875.0414 - val_custom_acc: 0.3090\n",
      "Epoch 138/500\n",
      "24s - loss: 4933.5622 - custom_acc: 0.3593 - val_loss: 4875.0240 - val_custom_acc: 0.3090\n",
      "Epoch 139/500\n",
      "24s - loss: 4933.5097 - custom_acc: 0.3594 - val_loss: 4875.0073 - val_custom_acc: 0.3090\n",
      "Epoch 140/500\n",
      "24s - loss: 4933.4575 - custom_acc: 0.3595 - val_loss: 4874.9906 - val_custom_acc: 0.3090\n",
      "Epoch 141/500\n",
      "24s - loss: 4933.4057 - custom_acc: 0.3595 - val_loss: 4874.9741 - val_custom_acc: 0.3089\n",
      "Epoch 142/500\n",
      "24s - loss: 4933.3542 - custom_acc: 0.3596 - val_loss: 4874.9580 - val_custom_acc: 0.3090\n",
      "Epoch 143/500\n",
      "24s - loss: 4933.3031 - custom_acc: 0.3596 - val_loss: 4874.9421 - val_custom_acc: 0.3090\n",
      "Epoch 144/500\n",
      "24s - loss: 4933.2521 - custom_acc: 0.3597 - val_loss: 4874.9260 - val_custom_acc: 0.3089\n",
      "Epoch 145/500\n",
      "24s - loss: 4933.2017 - custom_acc: 0.3597 - val_loss: 4874.9107 - val_custom_acc: 0.3088\n",
      "Epoch 146/500\n",
      "24s - loss: 4933.1515 - custom_acc: 0.3598 - val_loss: 4874.8955 - val_custom_acc: 0.3088\n",
      "Epoch 147/500\n",
      "24s - loss: 4933.1016 - custom_acc: 0.3599 - val_loss: 4874.8805 - val_custom_acc: 0.3088\n",
      "Epoch 148/500\n",
      "24s - loss: 4933.0521 - custom_acc: 0.3600 - val_loss: 4874.8658 - val_custom_acc: 0.3088\n",
      "Epoch 149/500\n",
      "24s - loss: 4933.0029 - custom_acc: 0.3600 - val_loss: 4874.8510 - val_custom_acc: 0.3089\n",
      "Epoch 150/500\n",
      "24s - loss: 4932.9540 - custom_acc: 0.3601 - val_loss: 4874.8363 - val_custom_acc: 0.3088\n",
      "Epoch 151/500\n",
      "24s - loss: 4932.9054 - custom_acc: 0.3601 - val_loss: 4874.8223 - val_custom_acc: 0.3088\n",
      "Epoch 152/500\n",
      "24s - loss: 4932.8570 - custom_acc: 0.3602 - val_loss: 4874.8082 - val_custom_acc: 0.3088\n",
      "Epoch 153/500\n",
      "24s - loss: 4932.8089 - custom_acc: 0.3602 - val_loss: 4874.7945 - val_custom_acc: 0.3088\n",
      "Epoch 154/500\n",
      "24s - loss: 4932.7611 - custom_acc: 0.3603 - val_loss: 4874.7807 - val_custom_acc: 0.3088\n",
      "Epoch 155/500\n",
      "24s - loss: 4932.7136 - custom_acc: 0.3604 - val_loss: 4874.7674 - val_custom_acc: 0.3089\n",
      "Epoch 156/500\n",
      "24s - loss: 4932.6664 - custom_acc: 0.3604 - val_loss: 4874.7542 - val_custom_acc: 0.3089\n",
      "Epoch 157/500\n",
      "24s - loss: 4932.6195 - custom_acc: 0.3605 - val_loss: 4874.7411 - val_custom_acc: 0.3089\n",
      "Epoch 158/500\n",
      "24s - loss: 4932.5727 - custom_acc: 0.3605 - val_loss: 4874.7283 - val_custom_acc: 0.3089\n",
      "Epoch 159/500\n",
      "24s - loss: 4932.5264 - custom_acc: 0.3606 - val_loss: 4874.7153 - val_custom_acc: 0.3089\n",
      "Epoch 160/500\n",
      "24s - loss: 4932.4802 - custom_acc: 0.3607 - val_loss: 4874.7030 - val_custom_acc: 0.3090\n",
      "Epoch 161/500\n",
      "24s - loss: 4932.4343 - custom_acc: 0.3607 - val_loss: 4874.6906 - val_custom_acc: 0.3092\n",
      "Epoch 162/500\n",
      "24s - loss: 4932.3886 - custom_acc: 0.3608 - val_loss: 4874.6780 - val_custom_acc: 0.3092\n",
      "Epoch 163/500\n",
      "24s - loss: 4932.3432 - custom_acc: 0.3608 - val_loss: 4874.6660 - val_custom_acc: 0.3093\n",
      "Epoch 164/500\n",
      "24s - loss: 4932.2980 - custom_acc: 0.3609 - val_loss: 4874.6541 - val_custom_acc: 0.3093\n",
      "Epoch 165/500\n",
      "24s - loss: 4932.2530 - custom_acc: 0.3609 - val_loss: 4874.6424 - val_custom_acc: 0.3093\n",
      "Epoch 166/500\n",
      "24s - loss: 4932.2084 - custom_acc: 0.3610 - val_loss: 4874.6306 - val_custom_acc: 0.3093\n",
      "Epoch 167/500\n",
      "24s - loss: 4932.1639 - custom_acc: 0.3610 - val_loss: 4874.6193 - val_custom_acc: 0.3094\n",
      "Epoch 168/500\n",
      "24s - loss: 4932.1196 - custom_acc: 0.3611 - val_loss: 4874.6080 - val_custom_acc: 0.3094\n",
      "Epoch 169/500\n",
      "24s - loss: 4932.0756 - custom_acc: 0.3612 - val_loss: 4874.5968 - val_custom_acc: 0.3094\n",
      "Epoch 170/500\n",
      "24s - loss: 4932.0318 - custom_acc: 0.3612 - val_loss: 4874.5860 - val_custom_acc: 0.3093\n",
      "Epoch 171/500\n",
      "24s - loss: 4931.9883 - custom_acc: 0.3613 - val_loss: 4874.5749 - val_custom_acc: 0.3093\n",
      "Epoch 172/500\n",
      "24s - loss: 4931.9450 - custom_acc: 0.3613 - val_loss: 4874.5643 - val_custom_acc: 0.3094\n",
      "Epoch 173/500\n",
      "24s - loss: 4931.9018 - custom_acc: 0.3614 - val_loss: 4874.5537 - val_custom_acc: 0.3095\n",
      "Epoch 174/500\n",
      "24s - loss: 4931.8589 - custom_acc: 0.3614 - val_loss: 4874.5431 - val_custom_acc: 0.3095\n",
      "Epoch 175/500\n",
      "24s - loss: 4931.8162 - custom_acc: 0.3615 - val_loss: 4874.5328 - val_custom_acc: 0.3096\n",
      "Epoch 176/500\n",
      "24s - loss: 4931.7736 - custom_acc: 0.3615 - val_loss: 4874.5226 - val_custom_acc: 0.3096\n",
      "Epoch 177/500\n",
      "24s - loss: 4931.7314 - custom_acc: 0.3616 - val_loss: 4874.5127 - val_custom_acc: 0.3096\n",
      "Epoch 178/500\n",
      "24s - loss: 4931.6893 - custom_acc: 0.3617 - val_loss: 4874.5028 - val_custom_acc: 0.3096\n",
      "Epoch 179/500\n",
      "24s - loss: 4931.6474 - custom_acc: 0.3617 - val_loss: 4874.4930 - val_custom_acc: 0.3096\n",
      "Epoch 180/500\n",
      "24s - loss: 4931.6057 - custom_acc: 0.3618 - val_loss: 4874.4835 - val_custom_acc: 0.3096\n",
      "Epoch 181/500\n",
      "24s - loss: 4931.5641 - custom_acc: 0.3618 - val_loss: 4874.4740 - val_custom_acc: 0.3096\n",
      "Epoch 182/500\n",
      "24s - loss: 4931.5228 - custom_acc: 0.3619 - val_loss: 4874.4645 - val_custom_acc: 0.3095\n",
      "Epoch 183/500\n",
      "24s - loss: 4931.4817 - custom_acc: 0.3619 - val_loss: 4874.4554 - val_custom_acc: 0.3095\n",
      "Epoch 184/500\n",
      "24s - loss: 4931.4408 - custom_acc: 0.3620 - val_loss: 4874.4461 - val_custom_acc: 0.3095\n",
      "Epoch 185/500\n",
      "24s - loss: 4931.4001 - custom_acc: 0.3621 - val_loss: 4874.4371 - val_custom_acc: 0.3095\n",
      "Epoch 186/500\n",
      "24s - loss: 4931.3595 - custom_acc: 0.3621 - val_loss: 4874.4284 - val_custom_acc: 0.3095\n",
      "Epoch 187/500\n",
      "24s - loss: 4931.3191 - custom_acc: 0.3622 - val_loss: 4874.4195 - val_custom_acc: 0.3095\n",
      "Epoch 188/500\n",
      "24s - loss: 4931.2789 - custom_acc: 0.3622 - val_loss: 4874.4108 - val_custom_acc: 0.3096\n",
      "Epoch 189/500\n",
      "24s - loss: 4931.2389 - custom_acc: 0.3623 - val_loss: 4874.4025 - val_custom_acc: 0.3096\n",
      "Epoch 190/500\n",
      "24s - loss: 4931.1990 - custom_acc: 0.3623 - val_loss: 4874.3940 - val_custom_acc: 0.3097\n",
      "Epoch 191/500\n",
      "24s - loss: 4931.1594 - custom_acc: 0.3624 - val_loss: 4874.3856 - val_custom_acc: 0.3098\n",
      "Epoch 192/500\n",
      "24s - loss: 4931.1198 - custom_acc: 0.3624 - val_loss: 4874.3775 - val_custom_acc: 0.3098\n",
      "Epoch 193/500\n",
      "24s - loss: 4931.0805 - custom_acc: 0.3625 - val_loss: 4874.3692 - val_custom_acc: 0.3098\n",
      "Epoch 194/500\n",
      "24s - loss: 4931.0413 - custom_acc: 0.3625 - val_loss: 4874.3611 - val_custom_acc: 0.3098\n",
      "Epoch 195/500\n",
      "24s - loss: 4931.0023 - custom_acc: 0.3626 - val_loss: 4874.3533 - val_custom_acc: 0.3097\n",
      "Epoch 196/500\n",
      "24s - loss: 4930.9634 - custom_acc: 0.3626 - val_loss: 4874.3456 - val_custom_acc: 0.3098\n",
      "Epoch 197/500\n",
      "24s - loss: 4930.9247 - custom_acc: 0.3627 - val_loss: 4874.3380 - val_custom_acc: 0.3097\n",
      "Epoch 198/500\n",
      "24s - loss: 4930.8862 - custom_acc: 0.3627 - val_loss: 4874.3303 - val_custom_acc: 0.3097\n",
      "Epoch 199/500\n",
      "24s - loss: 4930.8478 - custom_acc: 0.3628 - val_loss: 4874.3229 - val_custom_acc: 0.3097\n",
      "Epoch 200/500\n",
      "24s - loss: 4930.8095 - custom_acc: 0.3629 - val_loss: 4874.3155 - val_custom_acc: 0.3096\n",
      "Epoch 201/500\n",
      "24s - loss: 4930.7715 - custom_acc: 0.3629 - val_loss: 4874.3084 - val_custom_acc: 0.3096\n",
      "Epoch 202/500\n",
      "24s - loss: 4930.7336 - custom_acc: 0.3630 - val_loss: 4874.3011 - val_custom_acc: 0.3097\n",
      "Epoch 203/500\n",
      "24s - loss: 4930.6958 - custom_acc: 0.3631 - val_loss: 4874.2939 - val_custom_acc: 0.3096\n",
      "Epoch 204/500\n",
      "24s - loss: 4930.6582 - custom_acc: 0.3631 - val_loss: 4874.2869 - val_custom_acc: 0.3096\n",
      "Epoch 205/500\n",
      "24s - loss: 4930.6207 - custom_acc: 0.3632 - val_loss: 4874.2801 - val_custom_acc: 0.3094\n",
      "Epoch 206/500\n",
      "24s - loss: 4930.5834 - custom_acc: 0.3632 - val_loss: 4874.2732 - val_custom_acc: 0.3095\n",
      "Epoch 207/500\n",
      "24s - loss: 4930.5461 - custom_acc: 0.3633 - val_loss: 4874.2666 - val_custom_acc: 0.3094\n",
      "Epoch 208/500\n",
      "24s - loss: 4930.5091 - custom_acc: 0.3633 - val_loss: 4874.2598 - val_custom_acc: 0.3095\n",
      "Epoch 209/500\n",
      "24s - loss: 4930.4722 - custom_acc: 0.3634 - val_loss: 4874.2531 - val_custom_acc: 0.3094\n",
      "Epoch 210/500\n",
      "24s - loss: 4930.4354 - custom_acc: 0.3635 - val_loss: 4874.2468 - val_custom_acc: 0.3094\n",
      "Epoch 211/500\n",
      "24s - loss: 4930.3987 - custom_acc: 0.3635 - val_loss: 4874.2405 - val_custom_acc: 0.3095\n",
      "Epoch 212/500\n",
      "24s - loss: 4930.3622 - custom_acc: 0.3636 - val_loss: 4874.2342 - val_custom_acc: 0.3094\n",
      "Epoch 213/500\n",
      "24s - loss: 4930.3258 - custom_acc: 0.3636 - val_loss: 4874.2280 - val_custom_acc: 0.3095\n",
      "Epoch 214/500\n",
      "24s - loss: 4930.2896 - custom_acc: 0.3637 - val_loss: 4874.2219 - val_custom_acc: 0.3095\n",
      "Epoch 215/500\n",
      "24s - loss: 4930.2534 - custom_acc: 0.3638 - val_loss: 4874.2156 - val_custom_acc: 0.3095\n",
      "Epoch 216/500\n",
      "24s - loss: 4930.2174 - custom_acc: 0.3638 - val_loss: 4874.2098 - val_custom_acc: 0.3095\n",
      "Epoch 217/500\n",
      "24s - loss: 4930.1815 - custom_acc: 0.3639 - val_loss: 4874.2040 - val_custom_acc: 0.3096\n",
      "Epoch 218/500\n",
      "24s - loss: 4930.1458 - custom_acc: 0.3639 - val_loss: 4874.1981 - val_custom_acc: 0.3097\n",
      "Epoch 219/500\n",
      "24s - loss: 4930.1102 - custom_acc: 0.3639 - val_loss: 4874.1923 - val_custom_acc: 0.3096\n",
      "Epoch 220/500\n",
      "24s - loss: 4930.0747 - custom_acc: 0.3640 - val_loss: 4874.1868 - val_custom_acc: 0.3096\n",
      "Epoch 221/500\n",
      "24s - loss: 4930.0393 - custom_acc: 0.3641 - val_loss: 4874.1808 - val_custom_acc: 0.3096\n",
      "Epoch 222/500\n",
      "24s - loss: 4930.0041 - custom_acc: 0.3641 - val_loss: 4874.1757 - val_custom_acc: 0.3095\n",
      "Epoch 223/500\n",
      "24s - loss: 4929.9690 - custom_acc: 0.3641 - val_loss: 4874.1704 - val_custom_acc: 0.3095\n",
      "Epoch 224/500\n",
      "24s - loss: 4929.9339 - custom_acc: 0.3642 - val_loss: 4874.1648 - val_custom_acc: 0.3095\n",
      "Epoch 225/500\n",
      "24s - loss: 4929.8990 - custom_acc: 0.3643 - val_loss: 4874.1593 - val_custom_acc: 0.3095\n",
      "Epoch 226/500\n",
      "24s - loss: 4929.8642 - custom_acc: 0.3643 - val_loss: 4874.1544 - val_custom_acc: 0.3094\n",
      "Epoch 227/500\n",
      "24s - loss: 4929.8295 - custom_acc: 0.3644 - val_loss: 4874.1492 - val_custom_acc: 0.3094\n",
      "Epoch 228/500\n",
      "24s - loss: 4929.7949 - custom_acc: 0.3645 - val_loss: 4874.1439 - val_custom_acc: 0.3093\n",
      "Epoch 229/500\n",
      "24s - loss: 4929.7605 - custom_acc: 0.3645 - val_loss: 4874.1392 - val_custom_acc: 0.3093\n",
      "Epoch 230/500\n",
      "24s - loss: 4929.7262 - custom_acc: 0.3645 - val_loss: 4874.1341 - val_custom_acc: 0.3093\n",
      "Epoch 231/500\n",
      "24s - loss: 4929.6918 - custom_acc: 0.3646 - val_loss: 4874.1293 - val_custom_acc: 0.3093\n",
      "Epoch 232/500\n",
      "24s - loss: 4929.6577 - custom_acc: 0.3647 - val_loss: 4874.1242 - val_custom_acc: 0.3094\n",
      "Epoch 233/500\n",
      "24s - loss: 4929.6237 - custom_acc: 0.3647 - val_loss: 4874.1196 - val_custom_acc: 0.3094\n",
      "Epoch 234/500\n",
      "24s - loss: 4929.5898 - custom_acc: 0.3648 - val_loss: 4874.1150 - val_custom_acc: 0.3094\n",
      "Epoch 235/500\n",
      "24s - loss: 4929.5560 - custom_acc: 0.3649 - val_loss: 4874.1102 - val_custom_acc: 0.3094\n",
      "Epoch 236/500\n",
      "24s - loss: 4929.5222 - custom_acc: 0.3649 - val_loss: 4874.1059 - val_custom_acc: 0.3094\n",
      "Epoch 237/500\n",
      "24s - loss: 4929.4886 - custom_acc: 0.3650 - val_loss: 4874.1013 - val_custom_acc: 0.3094\n",
      "Epoch 238/500\n",
      "24s - loss: 4929.4551 - custom_acc: 0.3651 - val_loss: 4874.0967 - val_custom_acc: 0.3094\n",
      "Epoch 239/500\n",
      "24s - loss: 4929.4217 - custom_acc: 0.3651 - val_loss: 4874.0925 - val_custom_acc: 0.3094\n",
      "Epoch 240/500\n",
      "24s - loss: 4929.3884 - custom_acc: 0.3652 - val_loss: 4874.0883 - val_custom_acc: 0.3094\n",
      "Epoch 241/500\n",
      "24s - loss: 4929.3552 - custom_acc: 0.3652 - val_loss: 4874.0840 - val_custom_acc: 0.3094\n",
      "Epoch 242/500\n",
      "24s - loss: 4929.3221 - custom_acc: 0.3652 - val_loss: 4874.0798 - val_custom_acc: 0.3093\n",
      "Epoch 243/500\n",
      "24s - loss: 4929.2891 - custom_acc: 0.3653 - val_loss: 4874.0753 - val_custom_acc: 0.3093\n",
      "Epoch 244/500\n",
      "24s - loss: 4929.2561 - custom_acc: 0.3653 - val_loss: 4874.0715 - val_custom_acc: 0.3093\n",
      "Epoch 245/500\n",
      "24s - loss: 4929.2233 - custom_acc: 0.3654 - val_loss: 4874.0673 - val_custom_acc: 0.3093\n",
      "Epoch 246/500\n",
      "24s - loss: 4929.1906 - custom_acc: 0.3655 - val_loss: 4874.0634 - val_custom_acc: 0.3093\n",
      "Epoch 247/500\n",
      "24s - loss: 4929.1579 - custom_acc: 0.3656 - val_loss: 4874.0592 - val_custom_acc: 0.3093\n",
      "Epoch 248/500\n",
      "24s - loss: 4929.1253 - custom_acc: 0.3656 - val_loss: 4874.0554 - val_custom_acc: 0.3093\n",
      "Epoch 249/500\n",
      "24s - loss: 4929.0929 - custom_acc: 0.3657 - val_loss: 4874.0517 - val_custom_acc: 0.3093\n",
      "Epoch 250/500\n",
      "24s - loss: 4929.0606 - custom_acc: 0.3657 - val_loss: 4874.0479 - val_custom_acc: 0.3093\n",
      "Epoch 251/500\n",
      "24s - loss: 4929.0283 - custom_acc: 0.3658 - val_loss: 4874.0444 - val_custom_acc: 0.3092\n",
      "Epoch 252/500\n",
      "24s - loss: 4928.9961 - custom_acc: 0.3658 - val_loss: 4874.0405 - val_custom_acc: 0.3092\n",
      "Epoch 253/500\n",
      "24s - loss: 4928.9640 - custom_acc: 0.3659 - val_loss: 4874.0371 - val_custom_acc: 0.3092\n",
      "Epoch 254/500\n",
      "24s - loss: 4928.9320 - custom_acc: 0.3659 - val_loss: 4874.0335 - val_custom_acc: 0.3093\n",
      "Epoch 255/500\n",
      "24s - loss: 4928.9001 - custom_acc: 0.3660 - val_loss: 4874.0300 - val_custom_acc: 0.3094\n",
      "Epoch 256/500\n",
      "24s - loss: 4928.8682 - custom_acc: 0.3660 - val_loss: 4874.0265 - val_custom_acc: 0.3094\n",
      "Epoch 257/500\n",
      "24s - loss: 4928.8364 - custom_acc: 0.3661 - val_loss: 4874.0230 - val_custom_acc: 0.3094\n",
      "Epoch 258/500\n",
      "24s - loss: 4928.8048 - custom_acc: 0.3661 - val_loss: 4874.0196 - val_custom_acc: 0.3094\n",
      "Epoch 259/500\n",
      "24s - loss: 4928.7731 - custom_acc: 0.3661 - val_loss: 4874.0163 - val_custom_acc: 0.3094\n",
      "Epoch 260/500\n",
      "24s - loss: 4928.7417 - custom_acc: 0.3662 - val_loss: 4874.0129 - val_custom_acc: 0.3094\n",
      "Epoch 261/500\n",
      "24s - loss: 4928.7102 - custom_acc: 0.3662 - val_loss: 4874.0096 - val_custom_acc: 0.3094\n",
      "Epoch 262/500\n",
      "24s - loss: 4928.6789 - custom_acc: 0.3663 - val_loss: 4874.0064 - val_custom_acc: 0.3095\n",
      "Epoch 263/500\n",
      "24s - loss: 4928.6477 - custom_acc: 0.3663 - val_loss: 4874.0034 - val_custom_acc: 0.3094\n",
      "Epoch 264/500\n",
      "24s - loss: 4928.6165 - custom_acc: 0.3664 - val_loss: 4874.0001 - val_custom_acc: 0.3094\n",
      "Epoch 265/500\n",
      "24s - loss: 4928.5853 - custom_acc: 0.3665 - val_loss: 4873.9969 - val_custom_acc: 0.3094\n",
      "Epoch 266/500\n",
      "24s - loss: 4928.5543 - custom_acc: 0.3665 - val_loss: 4873.9940 - val_custom_acc: 0.3094\n",
      "Epoch 267/500\n",
      "24s - loss: 4928.5233 - custom_acc: 0.3665 - val_loss: 4873.9909 - val_custom_acc: 0.3093\n",
      "Epoch 268/500\n",
      "24s - loss: 4928.4925 - custom_acc: 0.3666 - val_loss: 4873.9880 - val_custom_acc: 0.3093\n",
      "Epoch 269/500\n",
      "24s - loss: 4928.4617 - custom_acc: 0.3666 - val_loss: 4873.9851 - val_custom_acc: 0.3093\n",
      "Epoch 270/500\n",
      "24s - loss: 4928.4310 - custom_acc: 0.3667 - val_loss: 4873.9821 - val_custom_acc: 0.3094\n",
      "Epoch 271/500\n",
      "24s - loss: 4928.4003 - custom_acc: 0.3667 - val_loss: 4873.9793 - val_custom_acc: 0.3093\n",
      "Epoch 272/500\n",
      "24s - loss: 4928.3698 - custom_acc: 0.3668 - val_loss: 4873.9764 - val_custom_acc: 0.3093\n",
      "Epoch 273/500\n",
      "24s - loss: 4928.3393 - custom_acc: 0.3669 - val_loss: 4873.9736 - val_custom_acc: 0.3092\n",
      "Epoch 274/500\n",
      "24s - loss: 4928.3089 - custom_acc: 0.3669 - val_loss: 4873.9707 - val_custom_acc: 0.3093\n",
      "Epoch 275/500\n",
      "24s - loss: 4928.2786 - custom_acc: 0.3669 - val_loss: 4873.9681 - val_custom_acc: 0.3092\n",
      "Epoch 276/500\n",
      "24s - loss: 4928.2483 - custom_acc: 0.3670 - val_loss: 4873.9653 - val_custom_acc: 0.3093\n",
      "Epoch 277/500\n",
      "24s - loss: 4928.2182 - custom_acc: 0.3671 - val_loss: 4873.9628 - val_custom_acc: 0.3092\n",
      "Epoch 278/500\n",
      "24s - loss: 4928.1880 - custom_acc: 0.3671 - val_loss: 4873.9601 - val_custom_acc: 0.3093\n",
      "Epoch 279/500\n",
      "24s - loss: 4928.1580 - custom_acc: 0.3672 - val_loss: 4873.9575 - val_custom_acc: 0.3093\n",
      "Epoch 280/500\n",
      "24s - loss: 4928.1280 - custom_acc: 0.3672 - val_loss: 4873.9551 - val_custom_acc: 0.3093\n",
      "Epoch 281/500\n",
      "24s - loss: 4928.0981 - custom_acc: 0.3672 - val_loss: 4873.9527 - val_custom_acc: 0.3094\n",
      "Epoch 282/500\n",
      "24s - loss: 4928.0682 - custom_acc: 0.3673 - val_loss: 4873.9499 - val_custom_acc: 0.3094\n",
      "Epoch 283/500\n",
      "24s - loss: 4928.0385 - custom_acc: 0.3674 - val_loss: 4873.9476 - val_custom_acc: 0.3093\n",
      "Epoch 284/500\n",
      "24s - loss: 4928.0089 - custom_acc: 0.3674 - val_loss: 4873.9454 - val_custom_acc: 0.3092\n",
      "Epoch 285/500\n",
      "24s - loss: 4927.9792 - custom_acc: 0.3675 - val_loss: 4873.9431 - val_custom_acc: 0.3092\n",
      "Epoch 286/500\n",
      "24s - loss: 4927.9496 - custom_acc: 0.3675 - val_loss: 4873.9407 - val_custom_acc: 0.3092\n",
      "Epoch 287/500\n",
      "24s - loss: 4927.9201 - custom_acc: 0.3676 - val_loss: 4873.9383 - val_custom_acc: 0.3092\n",
      "Epoch 288/500\n",
      "24s - loss: 4927.8907 - custom_acc: 0.3677 - val_loss: 4873.9359 - val_custom_acc: 0.3092\n",
      "Epoch 289/500\n",
      "24s - loss: 4927.8614 - custom_acc: 0.3677 - val_loss: 4873.9338 - val_custom_acc: 0.3092\n",
      "Epoch 290/500\n",
      "24s - loss: 4927.8321 - custom_acc: 0.3678 - val_loss: 4873.9318 - val_custom_acc: 0.3092\n",
      "Epoch 291/500\n",
      "24s - loss: 4927.8029 - custom_acc: 0.3678 - val_loss: 4873.9292 - val_custom_acc: 0.3093\n",
      "Epoch 292/500\n",
      "24s - loss: 4927.7738 - custom_acc: 0.3679 - val_loss: 4873.9270 - val_custom_acc: 0.3093\n",
      "Epoch 293/500\n",
      "24s - loss: 4927.7447 - custom_acc: 0.3679 - val_loss: 4873.9252 - val_custom_acc: 0.3093\n",
      "Epoch 294/500\n",
      "24s - loss: 4927.7157 - custom_acc: 0.3680 - val_loss: 4873.9228 - val_custom_acc: 0.3094\n",
      "Epoch 295/500\n",
      "24s - loss: 4927.6868 - custom_acc: 0.3680 - val_loss: 4873.9209 - val_custom_acc: 0.3094\n",
      "Epoch 296/500\n",
      "24s - loss: 4927.6579 - custom_acc: 0.3680 - val_loss: 4873.9188 - val_custom_acc: 0.3094\n",
      "Epoch 297/500\n",
      "24s - loss: 4927.6291 - custom_acc: 0.3681 - val_loss: 4873.9169 - val_custom_acc: 0.3094\n",
      "Epoch 298/500\n",
      "24s - loss: 4927.6003 - custom_acc: 0.3682 - val_loss: 4873.9148 - val_custom_acc: 0.3094\n",
      "Epoch 299/500\n",
      "24s - loss: 4927.5716 - custom_acc: 0.3683 - val_loss: 4873.9127 - val_custom_acc: 0.3094\n",
      "Epoch 300/500\n",
      "24s - loss: 4927.5430 - custom_acc: 0.3683 - val_loss: 4873.9111 - val_custom_acc: 0.3094\n",
      "Epoch 301/500\n",
      "24s - loss: 4927.5144 - custom_acc: 0.3684 - val_loss: 4873.9091 - val_custom_acc: 0.3094\n",
      "Epoch 302/500\n",
      "24s - loss: 4927.4860 - custom_acc: 0.3684 - val_loss: 4873.9071 - val_custom_acc: 0.3094\n",
      "Epoch 303/500\n",
      "24s - loss: 4927.4575 - custom_acc: 0.3684 - val_loss: 4873.9055 - val_custom_acc: 0.3095\n",
      "Epoch 304/500\n",
      "24s - loss: 4927.4291 - custom_acc: 0.3685 - val_loss: 4873.9037 - val_custom_acc: 0.3094\n",
      "Epoch 305/500\n",
      "24s - loss: 4927.4009 - custom_acc: 0.3685 - val_loss: 4873.9018 - val_custom_acc: 0.3094\n",
      "Epoch 306/500\n",
      "24s - loss: 4927.3727 - custom_acc: 0.3685 - val_loss: 4873.9000 - val_custom_acc: 0.3094\n",
      "Epoch 307/500\n",
      "24s - loss: 4927.3445 - custom_acc: 0.3686 - val_loss: 4873.8983 - val_custom_acc: 0.3094\n",
      "Epoch 308/500\n",
      "24s - loss: 4927.3163 - custom_acc: 0.3686 - val_loss: 4873.8968 - val_custom_acc: 0.3095\n",
      "Epoch 309/500\n",
      "24s - loss: 4927.2883 - custom_acc: 0.3687 - val_loss: 4873.8948 - val_custom_acc: 0.3094\n",
      "Epoch 310/500\n",
      "24s - loss: 4927.2603 - custom_acc: 0.3687 - val_loss: 4873.8933 - val_custom_acc: 0.3094\n",
      "Epoch 311/500\n",
      "24s - loss: 4927.2324 - custom_acc: 0.3687 - val_loss: 4873.8918 - val_custom_acc: 0.3094\n",
      "Epoch 312/500\n",
      "24s - loss: 4927.2045 - custom_acc: 0.3688 - val_loss: 4873.8900 - val_custom_acc: 0.3094\n",
      "Epoch 313/500\n",
      "24s - loss: 4927.1767 - custom_acc: 0.3689 - val_loss: 4873.8884 - val_custom_acc: 0.3094\n",
      "Epoch 314/500\n",
      "24s - loss: 4927.1489 - custom_acc: 0.3689 - val_loss: 4873.8867 - val_custom_acc: 0.3094\n",
      "Epoch 315/500\n",
      "24s - loss: 4927.1212 - custom_acc: 0.3689 - val_loss: 4873.8855 - val_custom_acc: 0.3093\n",
      "Epoch 316/500\n",
      "24s - loss: 4927.0935 - custom_acc: 0.3690 - val_loss: 4873.8838 - val_custom_acc: 0.3092\n",
      "Epoch 317/500\n",
      "24s - loss: 4927.0660 - custom_acc: 0.3690 - val_loss: 4873.8823 - val_custom_acc: 0.3092\n",
      "Epoch 318/500\n",
      "24s - loss: 4927.0384 - custom_acc: 0.3691 - val_loss: 4873.8808 - val_custom_acc: 0.3092\n",
      "Epoch 319/500\n",
      "24s - loss: 4927.0110 - custom_acc: 0.3691 - val_loss: 4873.8792 - val_custom_acc: 0.3092\n",
      "Epoch 320/500\n",
      "24s - loss: 4926.9837 - custom_acc: 0.3692 - val_loss: 4873.8779 - val_custom_acc: 0.3092\n",
      "Epoch 321/500\n",
      "24s - loss: 4926.9563 - custom_acc: 0.3692 - val_loss: 4873.8765 - val_custom_acc: 0.3092\n",
      "Epoch 322/500\n",
      "24s - loss: 4926.9289 - custom_acc: 0.3693 - val_loss: 4873.8751 - val_custom_acc: 0.3093\n",
      "Epoch 323/500\n",
      "24s - loss: 4926.9017 - custom_acc: 0.3693 - val_loss: 4873.8738 - val_custom_acc: 0.3093\n",
      "Epoch 324/500\n",
      "24s - loss: 4926.8746 - custom_acc: 0.3694 - val_loss: 4873.8725 - val_custom_acc: 0.3093\n",
      "Epoch 325/500\n",
      "24s - loss: 4926.8474 - custom_acc: 0.3694 - val_loss: 4873.8711 - val_custom_acc: 0.3092\n",
      "Epoch 326/500\n",
      "24s - loss: 4926.8204 - custom_acc: 0.3695 - val_loss: 4873.8697 - val_custom_acc: 0.3092\n",
      "Epoch 327/500\n",
      "24s - loss: 4926.7934 - custom_acc: 0.3695 - val_loss: 4873.8684 - val_custom_acc: 0.3092\n",
      "Epoch 328/500\n",
      "24s - loss: 4926.7664 - custom_acc: 0.3695 - val_loss: 4873.8672 - val_custom_acc: 0.3092\n",
      "Epoch 329/500\n",
      "24s - loss: 4926.7395 - custom_acc: 0.3696 - val_loss: 4873.8661 - val_custom_acc: 0.3092\n",
      "Epoch 330/500\n",
      "24s - loss: 4926.7126 - custom_acc: 0.3696 - val_loss: 4873.8650 - val_custom_acc: 0.3091\n",
      "Epoch 331/500\n",
      "24s - loss: 4926.6859 - custom_acc: 0.3697 - val_loss: 4873.8637 - val_custom_acc: 0.3091\n",
      "Epoch 332/500\n",
      "24s - loss: 4926.6592 - custom_acc: 0.3697 - val_loss: 4873.8627 - val_custom_acc: 0.3091\n",
      "Epoch 333/500\n",
      "24s - loss: 4926.6324 - custom_acc: 0.3697 - val_loss: 4873.8613 - val_custom_acc: 0.3091\n",
      "Epoch 334/500\n",
      "24s - loss: 4926.6058 - custom_acc: 0.3698 - val_loss: 4873.8601 - val_custom_acc: 0.3090\n",
      "Epoch 335/500\n",
      "24s - loss: 4926.5792 - custom_acc: 0.3698 - val_loss: 4873.8592 - val_custom_acc: 0.3091\n",
      "Epoch 336/500\n",
      "24s - loss: 4926.5527 - custom_acc: 0.3699 - val_loss: 4873.8581 - val_custom_acc: 0.3090\n",
      "Epoch 337/500\n",
      "24s - loss: 4926.5262 - custom_acc: 0.3699 - val_loss: 4873.8571 - val_custom_acc: 0.3091\n",
      "Epoch 338/500\n",
      "24s - loss: 4926.4998 - custom_acc: 0.3699 - val_loss: 4873.8560 - val_custom_acc: 0.3091\n",
      "Epoch 339/500\n",
      "24s - loss: 4926.4734 - custom_acc: 0.3700 - val_loss: 4873.8550 - val_custom_acc: 0.3091\n",
      "Epoch 340/500\n",
      "24s - loss: 4926.4472 - custom_acc: 0.3700 - val_loss: 4873.8539 - val_custom_acc: 0.3091\n",
      "Epoch 341/500\n",
      "24s - loss: 4926.4208 - custom_acc: 0.3700 - val_loss: 4873.8530 - val_custom_acc: 0.3091\n",
      "Epoch 342/500\n",
      "24s - loss: 4926.3946 - custom_acc: 0.3701 - val_loss: 4873.8520 - val_custom_acc: 0.3092\n",
      "Epoch 343/500\n",
      "24s - loss: 4926.3685 - custom_acc: 0.3701 - val_loss: 4873.8511 - val_custom_acc: 0.3091\n",
      "Epoch 344/500\n",
      "24s - loss: 4926.3424 - custom_acc: 0.3702 - val_loss: 4873.8502 - val_custom_acc: 0.3091\n",
      "Epoch 345/500\n",
      "24s - loss: 4926.3163 - custom_acc: 0.3702 - val_loss: 4873.8494 - val_custom_acc: 0.3091\n",
      "Epoch 346/500\n",
      "24s - loss: 4926.2904 - custom_acc: 0.3703 - val_loss: 4873.8483 - val_custom_acc: 0.3090\n",
      "Epoch 347/500\n",
      "24s - loss: 4926.2645 - custom_acc: 0.3703 - val_loss: 4873.8475 - val_custom_acc: 0.3090\n",
      "Epoch 348/500\n",
      "24s - loss: 4926.2385 - custom_acc: 0.3703 - val_loss: 4873.8468 - val_custom_acc: 0.3090\n",
      "Epoch 349/500\n",
      "24s - loss: 4926.2127 - custom_acc: 0.3704 - val_loss: 4873.8461 - val_custom_acc: 0.3090\n",
      "Epoch 350/500\n",
      "24s - loss: 4926.1869 - custom_acc: 0.3704 - val_loss: 4873.8451 - val_custom_acc: 0.3090\n",
      "Epoch 351/500\n",
      "24s - loss: 4926.1612 - custom_acc: 0.3705 - val_loss: 4873.8445 - val_custom_acc: 0.3090\n",
      "Epoch 352/500\n",
      "24s - loss: 4926.1355 - custom_acc: 0.3705 - val_loss: 4873.8438 - val_custom_acc: 0.3090\n",
      "Epoch 353/500\n",
      "24s - loss: 4926.1098 - custom_acc: 0.3706 - val_loss: 4873.8428 - val_custom_acc: 0.3090\n",
      "Epoch 354/500\n",
      "24s - loss: 4926.0843 - custom_acc: 0.3706 - val_loss: 4873.8421 - val_custom_acc: 0.3091\n",
      "Epoch 355/500\n",
      "24s - loss: 4926.0587 - custom_acc: 0.3706 - val_loss: 4873.8414 - val_custom_acc: 0.3090\n",
      "Epoch 356/500\n",
      "24s - loss: 4926.0332 - custom_acc: 0.3707 - val_loss: 4873.8408 - val_custom_acc: 0.3089\n",
      "Epoch 357/500\n",
      "24s - loss: 4926.0077 - custom_acc: 0.3707 - val_loss: 4873.8401 - val_custom_acc: 0.3089\n",
      "Epoch 358/500\n",
      "24s - loss: 4925.9824 - custom_acc: 0.3708 - val_loss: 4873.8396 - val_custom_acc: 0.3088\n",
      "Epoch 359/500\n",
      "24s - loss: 4925.9569 - custom_acc: 0.3708 - val_loss: 4873.8389 - val_custom_acc: 0.3088\n",
      "Epoch 360/500\n",
      "24s - loss: 4925.9317 - custom_acc: 0.3709 - val_loss: 4873.8379 - val_custom_acc: 0.3089\n",
      "Epoch 361/500\n",
      "24s - loss: 4925.9065 - custom_acc: 0.3709 - val_loss: 4873.8376 - val_custom_acc: 0.3089\n",
      "Epoch 362/500\n",
      "24s - loss: 4925.8813 - custom_acc: 0.3710 - val_loss: 4873.8369 - val_custom_acc: 0.3090\n",
      "Epoch 363/500\n",
      "24s - loss: 4925.8561 - custom_acc: 0.3710 - val_loss: 4873.8364 - val_custom_acc: 0.3089\n",
      "Epoch 364/500\n",
      "24s - loss: 4925.8311 - custom_acc: 0.3711 - val_loss: 4873.8361 - val_custom_acc: 0.3089\n",
      "Epoch 365/500\n",
      "24s - loss: 4925.8059 - custom_acc: 0.3711 - val_loss: 4873.8355 - val_custom_acc: 0.3089\n",
      "Epoch 366/500\n",
      "24s - loss: 4925.7809 - custom_acc: 0.3712 - val_loss: 4873.8351 - val_custom_acc: 0.3088\n",
      "Epoch 367/500\n",
      "24s - loss: 4925.7559 - custom_acc: 0.3712 - val_loss: 4873.8344 - val_custom_acc: 0.3088\n",
      "Epoch 368/500\n",
      "24s - loss: 4925.7310 - custom_acc: 0.3713 - val_loss: 4873.8340 - val_custom_acc: 0.3088\n",
      "Epoch 369/500\n",
      "24s - loss: 4925.7062 - custom_acc: 0.3713 - val_loss: 4873.8335 - val_custom_acc: 0.3089\n",
      "Epoch 370/500\n",
      "24s - loss: 4925.6813 - custom_acc: 0.3714 - val_loss: 4873.8331 - val_custom_acc: 0.3089\n",
      "Epoch 371/500\n",
      "24s - loss: 4925.6565 - custom_acc: 0.3714 - val_loss: 4873.8328 - val_custom_acc: 0.3089\n",
      "Epoch 372/500\n",
      "24s - loss: 4925.6318 - custom_acc: 0.3714 - val_loss: 4873.8324 - val_custom_acc: 0.3089\n",
      "Epoch 373/500\n",
      "24s - loss: 4925.6071 - custom_acc: 0.3715 - val_loss: 4873.8320 - val_custom_acc: 0.3089\n",
      "Epoch 374/500\n",
      "24s - loss: 4925.5824 - custom_acc: 0.3715 - val_loss: 4873.8315 - val_custom_acc: 0.3089\n",
      "Epoch 375/500\n",
      "24s - loss: 4925.5578 - custom_acc: 0.3715 - val_loss: 4873.8313 - val_custom_acc: 0.3089\n",
      "Epoch 376/500\n",
      "24s - loss: 4925.5333 - custom_acc: 0.3716 - val_loss: 4873.8308 - val_custom_acc: 0.3088\n",
      "Epoch 377/500\n",
      "24s - loss: 4925.5088 - custom_acc: 0.3716 - val_loss: 4873.8305 - val_custom_acc: 0.3089\n",
      "Epoch 378/500\n",
      "24s - loss: 4925.4843 - custom_acc: 0.3716 - val_loss: 4873.8303 - val_custom_acc: 0.3088\n",
      "Epoch 379/500\n",
      "24s - loss: 4925.4599 - custom_acc: 0.3717 - val_loss: 4873.8300 - val_custom_acc: 0.3089\n",
      "Epoch 380/500\n",
      "24s - loss: 4925.4355 - custom_acc: 0.3717 - val_loss: 4873.8298 - val_custom_acc: 0.3089\n",
      "Epoch 381/500\n",
      "24s - loss: 4925.4112 - custom_acc: 0.3717 - val_loss: 4873.8296 - val_custom_acc: 0.3089\n",
      "Epoch 382/500\n",
      "24s - loss: 4925.3869 - custom_acc: 0.3718 - val_loss: 4873.8293 - val_custom_acc: 0.3089\n",
      "Epoch 383/500\n",
      "24s - loss: 4925.3626 - custom_acc: 0.3718 - val_loss: 4873.8289 - val_custom_acc: 0.3089\n",
      "Epoch 384/500\n",
      "24s - loss: 4925.3385 - custom_acc: 0.3719 - val_loss: 4873.8290 - val_custom_acc: 0.3089\n",
      "Epoch 385/500\n",
      "24s - loss: 4925.3143 - custom_acc: 0.3719 - val_loss: 4873.8287 - val_custom_acc: 0.3088\n",
      "Epoch 386/500\n",
      "24s - loss: 4925.2902 - custom_acc: 0.3720 - val_loss: 4873.8287 - val_custom_acc: 0.3088\n",
      "Epoch 387/500\n",
      "24s - loss: 4925.2661 - custom_acc: 0.3720 - val_loss: 4873.8283 - val_custom_acc: 0.3088\n",
      "Epoch 388/500\n",
      "24s - loss: 4925.2421 - custom_acc: 0.3721 - val_loss: 4873.8282 - val_custom_acc: 0.3089\n",
      "Epoch 389/500\n",
      "24s - loss: 4925.2181 - custom_acc: 0.3721 - val_loss: 4873.8281 - val_custom_acc: 0.3088\n",
      "Epoch 390/500\n",
      "24s - loss: 4925.1942 - custom_acc: 0.3721 - val_loss: 4873.8279 - val_custom_acc: 0.3088\n",
      "Epoch 391/500\n",
      "24s - loss: 4925.1702 - custom_acc: 0.3722 - val_loss: 4873.8280 - val_custom_acc: 0.3087\n",
      "Epoch 392/500\n",
      "24s - loss: 4925.1463 - custom_acc: 0.3722 - val_loss: 4873.8278 - val_custom_acc: 0.3088\n",
      "Epoch 393/500\n",
      "24s - loss: 4925.1225 - custom_acc: 0.3723 - val_loss: 4873.8279 - val_custom_acc: 0.3088\n",
      "Epoch 394/500\n",
      "24s - loss: 4925.0987 - custom_acc: 0.3723 - val_loss: 4873.8278 - val_custom_acc: 0.3089\n",
      "Epoch 395/500\n",
      "24s - loss: 4925.0750 - custom_acc: 0.3724 - val_loss: 4873.8278 - val_custom_acc: 0.3089\n",
      "Epoch 396/500\n",
      "24s - loss: 4925.0514 - custom_acc: 0.3724 - val_loss: 4873.8278 - val_custom_acc: 0.3089\n",
      "Epoch 397/500\n",
      "24s - loss: 4925.0276 - custom_acc: 0.3724 - val_loss: 4873.8276 - val_custom_acc: 0.3089\n",
      "Epoch 398/500\n",
      "24s - loss: 4925.0040 - custom_acc: 0.3725 - val_loss: 4873.8280 - val_custom_acc: 0.3090\n",
      "Epoch 399/500\n",
      "24s - loss: 4924.9805 - custom_acc: 0.3725 - val_loss: 4873.8282 - val_custom_acc: 0.3090\n",
      "Epoch 400/500\n",
      "24s - loss: 4924.9569 - custom_acc: 0.3726 - val_loss: 4873.8278 - val_custom_acc: 0.3090\n",
      "Epoch 401/500\n",
      "24s - loss: 4924.9334 - custom_acc: 0.3726 - val_loss: 4873.8279 - val_custom_acc: 0.3089\n",
      "Epoch 402/500\n",
      "24s - loss: 4924.9100 - custom_acc: 0.3726 - val_loss: 4873.8280 - val_custom_acc: 0.3089\n",
      "Epoch 403/500\n",
      "24s - loss: 4924.8866 - custom_acc: 0.3727 - val_loss: 4873.8280 - val_custom_acc: 0.3089\n",
      "Epoch 404/500\n",
      "24s - loss: 4924.8632 - custom_acc: 0.3727 - val_loss: 4873.8282 - val_custom_acc: 0.3090\n",
      "Epoch 405/500\n",
      "24s - loss: 4924.8398 - custom_acc: 0.3727 - val_loss: 4873.8282 - val_custom_acc: 0.3090\n",
      "Epoch 406/500\n",
      "24s - loss: 4924.8167 - custom_acc: 0.3728 - val_loss: 4873.8282 - val_custom_acc: 0.3089\n",
      "Epoch 407/500\n",
      "24s - loss: 4924.7933 - custom_acc: 0.3728 - val_loss: 4873.8286 - val_custom_acc: 0.3089\n",
      "Epoch 408/500\n",
      "24s - loss: 4924.7701 - custom_acc: 0.3729 - val_loss: 4873.8289 - val_custom_acc: 0.3089\n",
      "Epoch 409/500\n",
      "24s - loss: 4924.7470 - custom_acc: 0.3729 - val_loss: 4873.8288 - val_custom_acc: 0.3089\n",
      "Epoch 410/500\n",
      "24s - loss: 4924.7238 - custom_acc: 0.3730 - val_loss: 4873.8289 - val_custom_acc: 0.3090\n",
      "Epoch 411/500\n",
      "24s - loss: 4924.7007 - custom_acc: 0.3730 - val_loss: 4873.8293 - val_custom_acc: 0.3090\n",
      "Epoch 412/500\n",
      "24s - loss: 4924.6777 - custom_acc: 0.3730 - val_loss: 4873.8294 - val_custom_acc: 0.3090\n",
      "Epoch 413/500\n",
      "24s - loss: 4924.6547 - custom_acc: 0.3731 - val_loss: 4873.8298 - val_custom_acc: 0.3090\n",
      "Epoch 414/500\n",
      "24s - loss: 4924.6317 - custom_acc: 0.3731 - val_loss: 4873.8299 - val_custom_acc: 0.3090\n",
      "Epoch 415/500\n",
      "24s - loss: 4924.6087 - custom_acc: 0.3731 - val_loss: 4873.8303 - val_custom_acc: 0.3090\n",
      "Epoch 416/500\n",
      "24s - loss: 4924.5858 - custom_acc: 0.3732 - val_loss: 4873.8305 - val_custom_acc: 0.3089\n",
      "Epoch 417/500\n",
      "24s - loss: 4924.5630 - custom_acc: 0.3732 - val_loss: 4873.8309 - val_custom_acc: 0.3090\n",
      "Epoch 418/500\n",
      "24s - loss: 4924.5402 - custom_acc: 0.3733 - val_loss: 4873.8313 - val_custom_acc: 0.3089\n",
      "Epoch 419/500\n",
      "24s - loss: 4924.5174 - custom_acc: 0.3733 - val_loss: 4873.8315 - val_custom_acc: 0.3089\n",
      "Epoch 420/500\n",
      "24s - loss: 4924.4946 - custom_acc: 0.3733 - val_loss: 4873.8319 - val_custom_acc: 0.3089\n",
      "Epoch 421/500\n",
      "24s - loss: 4924.4719 - custom_acc: 0.3734 - val_loss: 4873.8320 - val_custom_acc: 0.3089\n",
      "Epoch 422/500\n",
      "24s - loss: 4924.4492 - custom_acc: 0.3734 - val_loss: 4873.8322 - val_custom_acc: 0.3089\n",
      "Epoch 423/500\n",
      "24s - loss: 4924.4265 - custom_acc: 0.3734 - val_loss: 4873.8325 - val_custom_acc: 0.3089\n",
      "Epoch 424/500\n",
      "24s - loss: 4924.4040 - custom_acc: 0.3735 - val_loss: 4873.8331 - val_custom_acc: 0.3089\n",
      "Epoch 425/500\n",
      "24s - loss: 4924.3814 - custom_acc: 0.3735 - val_loss: 4873.8335 - val_custom_acc: 0.3089\n",
      "Epoch 426/500\n",
      "24s - loss: 4924.3588 - custom_acc: 0.3735 - val_loss: 4873.8336 - val_custom_acc: 0.3089\n",
      "Epoch 427/500\n",
      "24s - loss: 4924.3363 - custom_acc: 0.3735 - val_loss: 4873.8341 - val_custom_acc: 0.3090\n",
      "Epoch 428/500\n",
      "24s - loss: 4924.3139 - custom_acc: 0.3736 - val_loss: 4873.8346 - val_custom_acc: 0.3090\n",
      "Epoch 429/500\n",
      "24s - loss: 4924.2914 - custom_acc: 0.3736 - val_loss: 4873.8351 - val_custom_acc: 0.3090\n",
      "Epoch 430/500\n",
      "24s - loss: 4924.2691 - custom_acc: 0.3737 - val_loss: 4873.8356 - val_custom_acc: 0.3089\n",
      "Epoch 431/500\n",
      "24s - loss: 4924.2467 - custom_acc: 0.3737 - val_loss: 4873.8363 - val_custom_acc: 0.3089\n",
      "Epoch 432/500\n",
      "24s - loss: 4924.2244 - custom_acc: 0.3738 - val_loss: 4873.8364 - val_custom_acc: 0.3089\n",
      "Epoch 433/500\n",
      "24s - loss: 4924.2021 - custom_acc: 0.3738 - val_loss: 4873.8370 - val_custom_acc: 0.3089\n",
      "Epoch 434/500\n",
      "24s - loss: 4924.1799 - custom_acc: 0.3738 - val_loss: 4873.8373 - val_custom_acc: 0.3090\n",
      "Epoch 435/500\n",
      "24s - loss: 4924.1577 - custom_acc: 0.3739 - val_loss: 4873.8382 - val_custom_acc: 0.3089\n",
      "Epoch 436/500\n",
      "24s - loss: 4924.1355 - custom_acc: 0.3739 - val_loss: 4873.8383 - val_custom_acc: 0.3090\n",
      "Epoch 437/500\n",
      "24s - loss: 4924.1134 - custom_acc: 0.3739 - val_loss: 4873.8389 - val_custom_acc: 0.3089\n",
      "Epoch 438/500\n",
      "24s - loss: 4924.0913 - custom_acc: 0.3740 - val_loss: 4873.8394 - val_custom_acc: 0.3089\n",
      "Epoch 439/500\n",
      "24s - loss: 4924.0692 - custom_acc: 0.3740 - val_loss: 4873.8401 - val_custom_acc: 0.3089\n",
      "Epoch 440/500\n",
      "24s - loss: 4924.0472 - custom_acc: 0.3740 - val_loss: 4873.8405 - val_custom_acc: 0.3088\n",
      "Epoch 441/500\n",
      "24s - loss: 4924.0253 - custom_acc: 0.3740 - val_loss: 4873.8412 - val_custom_acc: 0.3088\n",
      "Epoch 442/500\n",
      "24s - loss: 4924.0033 - custom_acc: 0.3741 - val_loss: 4873.8417 - val_custom_acc: 0.3089\n",
      "Epoch 443/500\n",
      "24s - loss: 4923.9813 - custom_acc: 0.3741 - val_loss: 4873.8424 - val_custom_acc: 0.3089\n",
      "Epoch 444/500\n",
      "25s - loss: 4923.9594 - custom_acc: 0.3742 - val_loss: 4873.8430 - val_custom_acc: 0.3089\n",
      "Epoch 445/500\n",
      "25s - loss: 4923.9376 - custom_acc: 0.3742 - val_loss: 4873.8436 - val_custom_acc: 0.3089\n",
      "Epoch 446/500\n",
      "25s - loss: 4923.9157 - custom_acc: 0.3743 - val_loss: 4873.8442 - val_custom_acc: 0.3089\n",
      "Epoch 447/500\n",
      "25s - loss: 4923.8940 - custom_acc: 0.3743 - val_loss: 4873.8449 - val_custom_acc: 0.3089\n",
      "Epoch 448/500\n",
      "25s - loss: 4923.8722 - custom_acc: 0.3744 - val_loss: 4873.8457 - val_custom_acc: 0.3089\n",
      "Epoch 449/500\n",
      "25s - loss: 4923.8505 - custom_acc: 0.3744 - val_loss: 4873.8463 - val_custom_acc: 0.3089\n",
      "Epoch 450/500\n",
      "25s - loss: 4923.8288 - custom_acc: 0.3744 - val_loss: 4873.8469 - val_custom_acc: 0.3090\n",
      "Epoch 451/500\n",
      "25s - loss: 4923.8071 - custom_acc: 0.3745 - val_loss: 4873.8475 - val_custom_acc: 0.3090\n",
      "Epoch 452/500\n",
      "25s - loss: 4923.7855 - custom_acc: 0.3745 - val_loss: 4873.8483 - val_custom_acc: 0.3091\n",
      "Epoch 453/500\n",
      "25s - loss: 4923.7639 - custom_acc: 0.3746 - val_loss: 4873.8490 - val_custom_acc: 0.3090\n",
      "Epoch 454/500\n",
      "25s - loss: 4923.7423 - custom_acc: 0.3746 - val_loss: 4873.8496 - val_custom_acc: 0.3091\n",
      "Epoch 455/500\n",
      "25s - loss: 4923.7208 - custom_acc: 0.3747 - val_loss: 4873.8505 - val_custom_acc: 0.3091\n",
      "Epoch 456/500\n",
      "25s - loss: 4923.6993 - custom_acc: 0.3747 - val_loss: 4873.8511 - val_custom_acc: 0.3090\n",
      "Epoch 457/500\n",
      "25s - loss: 4923.6779 - custom_acc: 0.3747 - val_loss: 4873.8519 - val_custom_acc: 0.3091\n",
      "Epoch 458/500\n",
      "25s - loss: 4923.6565 - custom_acc: 0.3748 - val_loss: 4873.8526 - val_custom_acc: 0.3090\n",
      "Epoch 459/500\n",
      "25s - loss: 4923.6351 - custom_acc: 0.3748 - val_loss: 4873.8533 - val_custom_acc: 0.3090\n",
      "Epoch 460/500\n",
      "25s - loss: 4923.6137 - custom_acc: 0.3749 - val_loss: 4873.8540 - val_custom_acc: 0.3090\n",
      "Epoch 461/500\n",
      "25s - loss: 4923.5923 - custom_acc: 0.3749 - val_loss: 4873.8551 - val_custom_acc: 0.3090\n",
      "Epoch 462/500\n",
      "25s - loss: 4923.5711 - custom_acc: 0.3749 - val_loss: 4873.8560 - val_custom_acc: 0.3089\n",
      "Epoch 463/500\n",
      "25s - loss: 4923.5499 - custom_acc: 0.3750 - val_loss: 4873.8565 - val_custom_acc: 0.3089\n",
      "Epoch 464/500\n",
      "26s - loss: 4923.5286 - custom_acc: 0.3750 - val_loss: 4873.8573 - val_custom_acc: 0.3089\n",
      "Epoch 465/500\n",
      "26s - loss: 4923.5074 - custom_acc: 0.3750 - val_loss: 4873.8581 - val_custom_acc: 0.3089\n",
      "Epoch 466/500\n",
      "25s - loss: 4923.4862 - custom_acc: 0.3751 - val_loss: 4873.8592 - val_custom_acc: 0.3089\n",
      "Epoch 467/500\n",
      "24s - loss: 4923.4651 - custom_acc: 0.3752 - val_loss: 4873.8600 - val_custom_acc: 0.3089\n",
      "Epoch 468/500\n",
      "24s - loss: 4923.4440 - custom_acc: 0.3752 - val_loss: 4873.8608 - val_custom_acc: 0.3090\n",
      "Epoch 469/500\n",
      "24s - loss: 4923.4229 - custom_acc: 0.3752 - val_loss: 4873.8615 - val_custom_acc: 0.3089\n",
      "Epoch 470/500\n",
      "24s - loss: 4923.4019 - custom_acc: 0.3753 - val_loss: 4873.8626 - val_custom_acc: 0.3090\n",
      "Epoch 471/500\n",
      "24s - loss: 4923.3809 - custom_acc: 0.3753 - val_loss: 4873.8637 - val_custom_acc: 0.3089\n",
      "Epoch 472/500\n",
      "24s - loss: 4923.3599 - custom_acc: 0.3753 - val_loss: 4873.8644 - val_custom_acc: 0.3089\n",
      "Epoch 473/500\n",
      "24s - loss: 4923.3390 - custom_acc: 0.3754 - val_loss: 4873.8653 - val_custom_acc: 0.3089\n",
      "Epoch 474/500\n",
      "24s - loss: 4923.3180 - custom_acc: 0.3754 - val_loss: 4873.8663 - val_custom_acc: 0.3089\n",
      "Epoch 475/500\n",
      "24s - loss: 4923.2971 - custom_acc: 0.3754 - val_loss: 4873.8674 - val_custom_acc: 0.3089\n",
      "Epoch 476/500\n",
      "24s - loss: 4923.2763 - custom_acc: 0.3755 - val_loss: 4873.8681 - val_custom_acc: 0.3089\n",
      "Epoch 477/500\n",
      "24s - loss: 4923.2554 - custom_acc: 0.3755 - val_loss: 4873.8692 - val_custom_acc: 0.3090\n",
      "Epoch 478/500\n",
      "24s - loss: 4923.2346 - custom_acc: 0.3756 - val_loss: 4873.8702 - val_custom_acc: 0.3089\n",
      "Epoch 479/500\n",
      "24s - loss: 4923.2139 - custom_acc: 0.3756 - val_loss: 4873.8711 - val_custom_acc: 0.3089\n",
      "Epoch 480/500\n",
      "24s - loss: 4923.1931 - custom_acc: 0.3756 - val_loss: 4873.8722 - val_custom_acc: 0.3089\n",
      "Epoch 481/500\n",
      "24s - loss: 4923.1725 - custom_acc: 0.3756 - val_loss: 4873.8730 - val_custom_acc: 0.3089\n",
      "Epoch 482/500\n",
      "24s - loss: 4923.1518 - custom_acc: 0.3757 - val_loss: 4873.8741 - val_custom_acc: 0.3089\n",
      "Epoch 483/500\n",
      "24s - loss: 4923.1312 - custom_acc: 0.3757 - val_loss: 4873.8751 - val_custom_acc: 0.3089\n",
      "Epoch 484/500\n",
      "24s - loss: 4923.1106 - custom_acc: 0.3757 - val_loss: 4873.8761 - val_custom_acc: 0.3089\n",
      "Epoch 485/500\n",
      "24s - loss: 4923.0900 - custom_acc: 0.3758 - val_loss: 4873.8773 - val_custom_acc: 0.3089\n",
      "Epoch 486/500\n",
      "24s - loss: 4923.0695 - custom_acc: 0.3758 - val_loss: 4873.8783 - val_custom_acc: 0.3089\n",
      "Epoch 487/500\n",
      "24s - loss: 4923.0489 - custom_acc: 0.3759 - val_loss: 4873.8792 - val_custom_acc: 0.3088\n",
      "Epoch 488/500\n",
      "24s - loss: 4923.0284 - custom_acc: 0.3759 - val_loss: 4873.8805 - val_custom_acc: 0.3088\n",
      "Epoch 489/500\n",
      "24s - loss: 4923.0079 - custom_acc: 0.3759 - val_loss: 4873.8815 - val_custom_acc: 0.3089\n",
      "Epoch 490/500\n",
      "24s - loss: 4922.9875 - custom_acc: 0.3760 - val_loss: 4873.8824 - val_custom_acc: 0.3088\n",
      "Epoch 491/500\n",
      "24s - loss: 4922.9671 - custom_acc: 0.3760 - val_loss: 4873.8836 - val_custom_acc: 0.3088\n",
      "Epoch 492/500\n",
      "24s - loss: 4922.9468 - custom_acc: 0.3760 - val_loss: 4873.8847 - val_custom_acc: 0.3088\n",
      "Epoch 493/500\n",
      "24s - loss: 4922.9264 - custom_acc: 0.3761 - val_loss: 4873.8858 - val_custom_acc: 0.3088\n",
      "Epoch 494/500\n",
      "24s - loss: 4922.9061 - custom_acc: 0.3761 - val_loss: 4873.8869 - val_custom_acc: 0.3088\n",
      "Epoch 495/500\n",
      "24s - loss: 4922.8858 - custom_acc: 0.3762 - val_loss: 4873.8881 - val_custom_acc: 0.3088\n",
      "Epoch 496/500\n",
      "24s - loss: 4922.8655 - custom_acc: 0.3762 - val_loss: 4873.8893 - val_custom_acc: 0.3088\n",
      "Epoch 497/500\n",
      "24s - loss: 4922.8453 - custom_acc: 0.3762 - val_loss: 4873.8904 - val_custom_acc: 0.3088\n",
      "Epoch 498/500\n",
      "24s - loss: 4922.8251 - custom_acc: 0.3762 - val_loss: 4873.8915 - val_custom_acc: 0.3089\n",
      "Epoch 499/500\n",
      "24s - loss: 4922.8049 - custom_acc: 0.3763 - val_loss: 4873.8928 - val_custom_acc: 0.3089\n",
      "Epoch 500/500\n",
      "25s - loss: 4922.7848 - custom_acc: 0.3763 - val_loss: 4873.8939 - val_custom_acc: 0.3089\n",
      "Done training\n"
     ]
    }
   ],
   "source": [
    "# verbose: 0 for no logging to stdout, 1 for progress bar logging, 2 for one log line per epoch.\n",
    "hist = model.fit(train_x, train_y, nb_epoch=EPOCHS, shuffle=False, verbose=2,\n",
    "                 validation_data=(test_x, test_y))\n",
    "print(\"Done training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.save(SAVE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6c1773464eee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvali_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvali_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hist' is not defined"
     ]
    }
   ],
   "source": [
    "vali_loss = list(hist.history.values())[1]\n",
    "plt.plot(range(EPOCHS), vali_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on cb513"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(SAVE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_acc = model.evaluate(test_x, test_y)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "prediction = model.predict(test_x[i:i+1])\n",
    "print(\"Shape:\", prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Expected:\\n\")\n",
    "_ = cullpdb_loader.print_residues(test_x[i], labels=test_y[i], two_d=TWO_D)\n",
    "print(\"\\nPredicted:\\n\")\n",
    "_ = cullpdb_loader.print_residues(test_x[i], labels=prediction[0], two_d=TWO_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:sdscbio]",
   "language": "python",
   "name": "conda-env-sdscbio-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
